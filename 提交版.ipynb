{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入必要库\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from glob import glob\n",
    "# from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取图片路径+标签文件\n",
    "train_df = pd.read_csv('visual_china_train.csv')\n",
    "for i in range(35000):\n",
    "    train_df['img_path'].iloc[i] = 'train/' + train_df['img_path'].iloc[i].split('/')[-1]\n",
    "img_paths = list(train_df['img_path'])\n",
    "\n",
    "#制作对于标签对应的哈希表\n",
    "def hash_tag(filepath):\n",
    "    fo = open(filepath, \"r\",encoding='utf-8')\n",
    "    hash_tag = {}\n",
    "    i = 0\n",
    "    for line in fo.readlines():                         \n",
    "        line = line.strip()                               \n",
    "        hash_tag[i] = line\n",
    "        i += 1\n",
    "    return hash_tag\n",
    "\n",
    "def load_ytrain(filepath):  \n",
    "    y_train = np.load(filepath)\n",
    "    y_train = y_train['tag_train']\n",
    "    \n",
    "    return y_train\n",
    "\n",
    "def arr2tag(arr):\n",
    "    tags = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        tag = []\n",
    "        index = np.where(arr[i] > 0.5)  \n",
    "        index = index[0].tolist()\n",
    "        tag =  [hash_tag[j] for j in index]\n",
    "\n",
    "        tags.append(tag)\n",
    "    return tags\n",
    "\n",
    "filepath = \"valid_tags.txt\"\n",
    "hash_tag = hash_tag(filepath)\n",
    "\n",
    "y_train = load_ytrain('tag_train.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train/2074d1cd049f38bb42198e18b23c0443230afb68.jpg',\n",
       " 'train/40591a781c7a3af93232a83dc2e1665d38b772bf.jpg',\n",
       " 'train/d41f7b535f13c15802aa393bc41d2b257992faee.jpg',\n",
       " 'train/f7ecc1a8182256885efce7edd40bfd84be6f05fb.jpg',\n",
       " 'train/09574a46403ab85188404d9383fe7fff51fac3a7.jpg',\n",
       " 'train/a386169ad6ffef3e1082084406f4a2cfbc698e6c.jpg',\n",
       " 'train/6df3766a0fee6493ed6daf5928dd16469c834dfd.jpg',\n",
       " 'train/ff67cccfbdbeee70d12f9b96678d200732be659d.jpg',\n",
       " 'train/e03bc9055cffad23a9fa96f5b4216ce26b79ae71.jpg',\n",
       " 'train/180aa34f37c9ab2600b4156b6bdab3aa42c418be.jpg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_paths[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0到11个月'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_tag[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 6941)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打乱并分割训练集和验证集\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2018)  \n",
    "X_train_path,y_train = shuffle(np.array(img_paths),y_train)\n",
    "X_train_path,X_val_path,y_train,y_val = train_test_split(X_train_path,y_train,test_size=0.2,random_state=0)\n",
    "X_train_path,X_val_path = X_train_path.tolist(),X_val_path.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['train/d06a3cf891f199c38f924ac531dafca3ab7c11ac.jpg',\n",
       "  'train/07f45aaa584000e57c6e458c518918ce2f650f3d.jpg',\n",
       "  'train/524a45d93cc271933d0f256a42c5b9a18d212a39.jpg',\n",
       "  'train/5f7d75849ac3f5843f6c0716b51e2af20c85ecec.jpg',\n",
       "  'train/0b09c36dc627e05819ead79bae716e7802d5e152.jpg',\n",
       "  'train/efa31b69c7e54ee6afb4fa996ef8f1c6087fb595.jpg',\n",
       "  'train/5d664de92e1fe65d81426dc167cb06b269b3df2f.jpg',\n",
       "  'train/aa5470708339820c26ae5f00ce4c7692c0d970b5.jpg',\n",
       "  'train/554b8e38f922179d7c6d4067fe91c7e08681bbca.jpg',\n",
       "  'train/618d265000c09c047442911b7f0b262f93949a0e.jpg'],\n",
       " ['train/2ae46e9b9ba3216b59a2d5586653d685c1c2ed71.jpg',\n",
       "  'train/82d48cba0f4812c12d614eae91c5f798d5b47ec0.jpg',\n",
       "  'train/86de6fa92945a342892fafdc1b226e2304ff2a54.jpg',\n",
       "  'train/d7a439b554bbd6bb52c8521eed23aad5045cf579.jpg',\n",
       "  'train/59481eae768f08ab8e25357e7f00a00a1faf8d2e.jpg',\n",
       "  'train/5cca490c0b9a10cca0caf9067d2a8d8a912bf312.jpg',\n",
       "  'train/5828ceb7feb72d201fa05e787eabce24c1e01f43.jpg',\n",
       "  'train/e48686a491b1124a188ce454ac9fa5d8360e8771.jpg',\n",
       "  'train/ac860e9d689c6a510e44fba175d5f1f89c1f8224.jpg',\n",
       "  'train/bf6d1a311c07d5fd3539c0f36397d82254f65899.jpg'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_path[:10],X_val_path[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义分批读取图片的生成器函数，不用将图片全部读入内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取图片函数\n",
    "def get_image(img_paths, img_size):\n",
    "    X = np.zeros((len(img_paths),img_size,img_size,3),dtype=np.uint8)\n",
    "    i = 0\n",
    "    blackIm = Image.new('RGB',(800, 800), 'Black')\n",
    "    for img_path in img_paths:\n",
    "        img = Image.open(img_path)\n",
    "        if img.mode != 'RGB':\n",
    "            img = img.convert(\"RGB\")\n",
    "        #平铺图片，不改变图片比例\n",
    "        width, height = img.size\n",
    "        copyIm = blackIm.copy()\n",
    "        for left in range(0, 800, width):\n",
    "            for top in range(0, 800, height):\n",
    "                copyIm.paste(img, (left, top))\n",
    "        img = copyIm\n",
    "        img = img.resize((img_size,img_size),Image.LANCZOS) #用LANCZOS插值算法，resize质量高\n",
    "        arr = np.asarray(img)\n",
    "        X[i,:,:,:] = arr\n",
    "        i += 1\n",
    "    return X\n",
    "\n",
    "def get_data_batch(X_path, Y, batch_size, img_size):\n",
    "    while 1:\n",
    "        for i in range(0, len(X_path), batch_size):\n",
    "            x = get_image(X_path[i:i+batch_size], img_size)\n",
    "            y = Y[i:i+batch_size]\n",
    "            yield x, y  #返回生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#建立keras后端计算fmeasure函数\n",
    "import keras.backend as K\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    # Calculates the precision\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    # Calculates the recall\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def fbeta_score(y_true, y_pred, beta=1):\n",
    "    # Calculates the F score, the weighted harmonic mean of precision and recall.\n",
    "    if beta < 0:\n",
    "        raise ValueError('The lowest choosable beta is zero (only precision).')\n",
    "    \n",
    "    # If there are no true positives, fix the F score at 0 like sklearn.\n",
    "    if K.sum(K.round(K.clip(y_true, 0, 1))) == 0:\n",
    "        return 0\n",
    "\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    bb = beta ** 2\n",
    "    fbeta_score = (1 + bb) * (p * r) / (bb * p + r + K.epsilon())\n",
    "    return fbeta_score*100\n",
    "\n",
    "def fmeasure(y_true, y_pred):\n",
    "    # Calculates the f-measure, the harmonic mean of precision and recall.\n",
    "    return fbeta_score(y_true, y_pred, beta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到生成器\n",
    "batch_size = 8\n",
    "img_size = 500\n",
    "train_generator = get_data_batch(X_train_path,y_train,batch_size=batch_size,img_size=img_size) \n",
    "val_generator = get_data_batch(X_val_path,y_val,batch_size=batch_size,img_size=img_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建预训练fine-tune模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1、预训练模型——InceptionResNetV2进行fine-tune训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "\n",
    "def MODEL(MODEL,img_size,out_dims,func=None,weights=None,include_top=False):\n",
    "    inputs = Input((img_size,img_size,3)) #实例化一个tensor\n",
    "    x = inputs\n",
    "    x = Lambda(func)(x)\n",
    "    \n",
    "    base_model = MODEL(weights=weights, include_top=include_top)\n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "#     x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(3072,activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(out_dims, activation='sigmoid')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_resnet_v2 (Model)  (None, None, None, 1536)  54336736  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3072)              4721664   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6941)              21329693  \n",
      "=================================================================\n",
      "Total params: 80,388,093\n",
      "Trainable params: 80,327,549\n",
      "Non-trainable params: 60,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "model = MODEL(InceptionResNetV2,500,out_dims=6941,func=preprocess_input,weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "   8/3500 [..............................] - ETA: 5:49:57 - loss: 0.6393 - acc: 0.6912 - fmeasure: 1.3470 - recall: 0.3470 - precision: 0.0069"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-be4bee9aa26d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m        \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m        verbose=1,steps_per_epoch=np.ceil(28000/batch_size),validation_steps=np.ceil(7000/batch_size))\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='Inresv2_weights_best.hdf5', \n",
    "                            monitor='val_fmeasure',verbose=1, save_best_only=True, mode='max')\n",
    "reduce = ReduceLROnPlateau(monitor='val_fmeasure',factor=0.5,patience=1,verbose=1,min_delta=1e-4, mode='max')\n",
    "\n",
    "adam = Adam(0.0001)\n",
    "model.compile(optimizer = adam,\n",
    "           loss='binary_crossentropy',\n",
    "           metrics=['accuracy',fmeasure,recall,precision])\n",
    "epochs = 20\n",
    "history = model.fit_generator(train_generator,\n",
    "       validation_data = val_generator,\n",
    "       epochs=epochs,\n",
    "       callbacks=[checkpointer,reduce],\n",
    "       verbose=1,steps_per_epoch=np.ceil(28000/batch_size),validation_steps=np.ceil(7000/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、预训练模型——Xception进行fine-tune训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "\n",
    "def MODEL(MODEL,img_size,out_dims,func=None,weights=None,include_top=False):\n",
    "    inputs = Input((img_size,img_size,3)) #实例化一个tensor\n",
    "    x = inputs\n",
    "    x = Lambda(func)(x)\n",
    "    \n",
    "    base_model = MODEL(weights=weights, include_top=include_top)\n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "#     x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(2048,activation='relu')(x) #此处全连接与InceptionResNetV2不同\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(out_dims, activation='sigmoid')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "xception (Model)             multiple                  20861480  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6941)              14222109  \n",
      "=================================================================\n",
      "Total params: 39,279,941\n",
      "Trainable params: 39,225,413\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.xception import preprocess_input\n",
    "model = MODEL(Xception,500,out_dims=6941,func=preprocess_input,weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  86/3500 [..............................] - ETA: 43:13 - loss: 0.1609 - acc: 0.9566 - fmeasure: 11.2254 - recall: 0.1124 - precision: 0.4973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2eebe1554702>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m        \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m        verbose=1,steps_per_epoch=np.ceil(28000/batch_size),validation_steps=np.ceil(7000/batch_size))\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='xception_weights_best.hdf5', \n",
    "                            monitor='val_fmeasure',verbose=1, save_best_only=True, mode='max')\n",
    "reduce = ReduceLROnPlateau(monitor='val_fmeasure',factor=0.5,patience=1,verbose=1,min_delta=1e-4, mode='max')\n",
    "\n",
    "adam = Adam(0.0001)\n",
    "model.compile(optimizer = adam,\n",
    "           loss='binary_crossentropy',\n",
    "           metrics=['accuracy',fmeasure,recall,precision])\n",
    "epochs = 20\n",
    "history = model.fit_generator(train_generator,\n",
    "       validation_data = val_generator,\n",
    "       epochs=epochs,\n",
    "       callbacks=[checkpointer,reduce],\n",
    "       verbose=1,steps_per_epoch=np.ceil(28000/batch_size),validation_steps=np.ceil(7000/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3、预训练模型——InceptionV3进行fine-tune训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "\n",
    "def MODEL(MODEL,img_size,out_dims,func=None,weights=None,include_top=False):\n",
    "    inputs = Input((img_size,img_size,3)) #实例化一个tensor\n",
    "    x = inputs\n",
    "    x = Lambda(func)(x)\n",
    "    \n",
    "    base_model = MODEL(weights=weights, include_top=include_top)\n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "#     x = Flatten()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(2048,activation='relu')(x) #此处全连接与InceptionResNetV2不同\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(out_dims, activation='sigmoid')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 500, 500, 3)       0         \n",
      "_________________________________________________________________\n",
      "inception_v3 (Model)         multiple                  21802784  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              4196352   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6941)              14222109  \n",
      "=================================================================\n",
      "Total params: 40,221,245\n",
      "Trainable params: 40,186,813\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.inception_v3 import preprocess_input\n",
    "model = MODEL(InceptionV3,500,out_dims=6941,func=preprocess_input,weights='imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  89/3500 [..............................] - ETA: 26:12 - loss: 0.1266 - acc: 0.9599 - fmeasure: 12.3410 - recall: 0.1136 - precision: 0.4840"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-537a6f12c538>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m        \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m        \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m        verbose=1,steps_per_epoch=np.ceil(28000/batch_size),validation_steps=np.ceil(7000/batch_size))\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1424\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1425\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1426\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    189\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    190\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1218\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1220\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1221\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='inceptionv3_weights_best.hdf5', \n",
    "                            monitor='val_fmeasure',verbose=1, save_best_only=True, mode='max')\n",
    "reduce = ReduceLROnPlateau(monitor='val_fmeasure',factor=0.5,patience=1,verbose=1,min_delta=1e-4, mode='max')\n",
    "\n",
    "adam = Adam(0.0001)\n",
    "model.compile(optimizer = adam,\n",
    "           loss='binary_crossentropy',\n",
    "           metrics=['accuracy',fmeasure,recall,precision])\n",
    "epochs = 20\n",
    "history = model.fit_generator(train_generator,\n",
    "       validation_data = val_generator,\n",
    "       epochs=epochs,\n",
    "       callbacks=[checkpointer,reduce],\n",
    "       verbose=1,steps_per_epoch=np.ceil(28000/batch_size),validation_steps=np.ceil(7000/batch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#得到所有训练集和测试集\n",
    "X_train_path = img_paths\n",
    "X_test_path = glob('test/*.jpg') #决赛测试集\n",
    "y_train2 = load_ytrain('tag_train.npz')\n",
    "\n",
    "#test的生成器中没有y\n",
    "def get_X_batch(X_path,batch_size,img_size):\n",
    "    while 1:\n",
    "        for i in range(0, len(X_path), batch_size):\n",
    "            x = get_image(X_path[i:i+batch_size], img_size)\n",
    "\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MODEL(MODEL,img_size,out_dims,func=None,weights=None,include_top=False):\n",
    "    inputs = Input((img_size,img_size,3)) \n",
    "    x = inputs\n",
    "    x = Lambda(func)(x)\n",
    "    \n",
    "    base_model = MODEL(weights=weights, include_top=include_top) \n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(2048,activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(out_dims, activation='sigmoid')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "def FeatureExtract(MODEL,img_size,func=None,weight_path=None):\n",
    "    base_model = build_MODEL(MODEL,img_size,out_dims=6941,func=func,weights=None)\n",
    "    base_model.load_weights(weight_path)\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.layers[-3].output)\n",
    "    \n",
    "    batch_size = 8\n",
    "    X_train_generator = get_X_batch(X_train_path, batch_size = batch_size, img_size = img_size)\n",
    "    X_test_generator = get_X_batch(X_test_path, batch_size = batch_size, img_size = img_size)\n",
    "    \n",
    "    train_features = model.predict_generator(X_train_generator, steps = np.ceil(len(X_train_path) / batch_size), verbose=1) \n",
    "    test_features = model.predict_generator(X_test_generator,steps = np.ceil(len(X_test_path) / batch_size), verbose=1)\n",
    "    \n",
    "    # 保存bottleneck特征\n",
    "    with h5py.File('%s_data.h5'%MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\",data = train_features)\n",
    "        h.create_dataset(\"test\",data = test_features)\n",
    "        h.create_dataset('label',data = y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分别提取特征向量，便于后面进行融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4375/4375 [==============================] - 758s 173ms/step\n",
      "827/827 [==============================] - 140s 169ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.inception_v3 import preprocess_input\n",
    "FeatureExtract(InceptionV3,500,func=preprocess_input,weight_path='inception_v3_weights_best_9_15_sigmoid_44.34666.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4375/4375 [==============================] - 725s 166ms/step\n",
      "827/827 [==============================] - 137s 165ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.xception import preprocess_input\n",
    "FeatureExtract(Xception,500,func=preprocess_input,weight_path='xception_weights_best_9_15_sigmoid.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MODEL2(MODEL,img_size,out_dims,func=None,weights=None,include_top=False):\n",
    "    inputs = Input((img_size,img_size,3))\n",
    "    x = inputs\n",
    "    x = Lambda(func)(x)\n",
    "    \n",
    "    base_model = MODEL(weights=weights, include_top=include_top) \n",
    "    x = base_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(3072,activation='relu')(x) #此处全连接与上面不同\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(out_dims, activation='sigmoid')(x)\n",
    "    model = Model(inputs, x)\n",
    "    return model\n",
    "\n",
    "def FeatureExtract(MODEL,img_size,func=None,weight_path=None):\n",
    "    base_model = build_MODEL2(MODEL,img_size,out_dims=6941,func=func,weights=None)\n",
    "    base_model.load_weights(weight_path)\n",
    "    model = Model(inputs=base_model.input, outputs=base_model.layers[-3].output)\n",
    "    \n",
    "    batch_size = 8\n",
    "    X_train_generator = get_X_batch(X_train_path, batch_size = batch_size, img_size = img_size)\n",
    "    X_test_generator = get_X_batch(X_test_path, batch_size = batch_size, img_size = img_size)\n",
    "    \n",
    "    train_features = model.predict_generator(X_train_generator, steps = np.ceil(len(X_train_path) / batch_size), verbose=1) \n",
    "    test_features = model.predict_generator(X_test_generator,steps = np.ceil(len(X_test_path) / batch_size), verbose=1)\n",
    "    \n",
    "    # 保存bottleneck特征\n",
    "    with h5py.File('%s_data.h5'%MODEL.__name__) as h:\n",
    "        h.create_dataset(\"train\",data = train_features)\n",
    "        h.create_dataset(\"test\",data = test_features)\n",
    "        h.create_dataset('label',data = y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4375/4375 [==============================] - 777s 178ms/step\n",
      "827/827 [==============================] - 146s 177ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "FeatureExtract(InceptionResNetV2,500,func=preprocess_input,weight_path='Inresv2_weights_best_9_13_46.49088.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "#将保存好的特征向量提取出来并进行串接融合\n",
    "for filename in ['Xception_data.h5','InceptionV3_data.h5','InceptionResNetV2_data.h5']:\n",
    "    with h5py.File(filename,'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['label'])\n",
    "X_train = np.concatenate(X_train,axis=1)\n",
    "X_test = np.concatenate(X_test,axis=1)\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2018)\n",
    "X_train,y_train = shuffle(X_train,y_train)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_val,y_train,y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28000 samples, validate on 7000 samples\n",
      "Epoch 1/200\n",
      "28000/28000 [==============================] - 23s 826us/step - loss: 0.0657 - acc: 0.9795 - fmeasure: 29.8287 - recall: 0.2165 - precision: 0.6356 - val_loss: 0.0193 - val_acc: 0.9956 - val_fmeasure: 41.9004 - val_recall: 0.2800 - val_precision: 0.8329\n",
      "\n",
      "Epoch 00001: val_fmeasure improved from -inf to 41.90044, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 2/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0196 - acc: 0.9955 - fmeasure: 44.7937 - recall: 0.3207 - precision: 0.7455 - val_loss: 0.0164 - val_acc: 0.9958 - val_fmeasure: 48.0120 - val_recall: 0.3394 - val_precision: 0.8210\n",
      "\n",
      "Epoch 00002: val_fmeasure improved from 41.90044 to 48.01198, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 3/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0172 - acc: 0.9957 - fmeasure: 48.8043 - recall: 0.3632 - precision: 0.7446 - val_loss: 0.0152 - val_acc: 0.9959 - val_fmeasure: 50.9690 - val_recall: 0.3714 - val_precision: 0.8126\n",
      "\n",
      "Epoch 00003: val_fmeasure improved from 48.01198 to 50.96903, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 4/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0160 - acc: 0.9957 - fmeasure: 51.0099 - recall: 0.3883 - precision: 0.7439 - val_loss: 0.0145 - val_acc: 0.9960 - val_fmeasure: 52.5269 - val_recall: 0.3883 - val_precision: 0.8122\n",
      "\n",
      "Epoch 00004: val_fmeasure improved from 50.96903 to 52.52689, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 5/200\n",
      "28000/28000 [==============================] - 11s 396us/step - loss: 0.0152 - acc: 0.9958 - fmeasure: 52.5249 - recall: 0.4049 - precision: 0.7481 - val_loss: 0.0140 - val_acc: 0.9960 - val_fmeasure: 53.6453 - val_recall: 0.4014 - val_precision: 0.8091\n",
      "\n",
      "Epoch 00005: val_fmeasure improved from 52.52689 to 53.64528, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 6/200\n",
      "28000/28000 [==============================] - 11s 393us/step - loss: 0.0146 - acc: 0.9959 - fmeasure: 53.5890 - recall: 0.4172 - precision: 0.7496 - val_loss: 0.0136 - val_acc: 0.9961 - val_fmeasure: 54.3677 - val_recall: 0.4092 - val_precision: 0.8103\n",
      "\n",
      "Epoch 00006: val_fmeasure improved from 53.64528 to 54.36768, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 7/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0141 - acc: 0.9959 - fmeasure: 54.5106 - recall: 0.4274 - precision: 0.7529 - val_loss: 0.0134 - val_acc: 0.9961 - val_fmeasure: 55.0835 - val_recall: 0.4176 - val_precision: 0.8095\n",
      "\n",
      "Epoch 00007: val_fmeasure improved from 54.36768 to 55.08346, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 8/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0137 - acc: 0.9960 - fmeasure: 55.2978 - recall: 0.4363 - precision: 0.7556 - val_loss: 0.0132 - val_acc: 0.9961 - val_fmeasure: 55.7043 - val_recall: 0.4252 - val_precision: 0.8081\n",
      "\n",
      "Epoch 00008: val_fmeasure improved from 55.08346 to 55.70433, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 9/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0133 - acc: 0.9960 - fmeasure: 55.9472 - recall: 0.4432 - precision: 0.7590 - val_loss: 0.0130 - val_acc: 0.9962 - val_fmeasure: 56.0551 - val_recall: 0.4291 - val_precision: 0.8088\n",
      "\n",
      "Epoch 00009: val_fmeasure improved from 55.70433 to 56.05510, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 10/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0130 - acc: 0.9961 - fmeasure: 56.5797 - recall: 0.4501 - precision: 0.7623 - val_loss: 0.0129 - val_acc: 0.9962 - val_fmeasure: 56.3827 - val_recall: 0.4325 - val_precision: 0.8104\n",
      "\n",
      "Epoch 00010: val_fmeasure improved from 56.05510 to 56.38266, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 11/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0128 - acc: 0.9961 - fmeasure: 57.1215 - recall: 0.4560 - precision: 0.7649 - val_loss: 0.0127 - val_acc: 0.9962 - val_fmeasure: 56.8661 - val_recall: 0.4392 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00011: val_fmeasure improved from 56.38266 to 56.86608, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 12/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0125 - acc: 0.9961 - fmeasure: 57.5483 - recall: 0.4607 - precision: 0.7670 - val_loss: 0.0126 - val_acc: 0.9962 - val_fmeasure: 57.2266 - val_recall: 0.4441 - val_precision: 0.8049\n",
      "\n",
      "Epoch 00012: val_fmeasure improved from 56.86608 to 57.22665, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 13/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0123 - acc: 0.9962 - fmeasure: 58.0972 - recall: 0.4666 - precision: 0.7701 - val_loss: 0.0126 - val_acc: 0.9962 - val_fmeasure: 57.4012 - val_recall: 0.4457 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00013: val_fmeasure improved from 57.22665 to 57.40124, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 14/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0121 - acc: 0.9962 - fmeasure: 58.4965 - recall: 0.4709 - precision: 0.7726 - val_loss: 0.0125 - val_acc: 0.9962 - val_fmeasure: 57.5455 - val_recall: 0.4471 - val_precision: 0.8078\n",
      "\n",
      "Epoch 00014: val_fmeasure improved from 57.40124 to 57.54545, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 15/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0119 - acc: 0.9962 - fmeasure: 58.8649 - recall: 0.4751 - precision: 0.7742 - val_loss: 0.0124 - val_acc: 0.9962 - val_fmeasure: 57.8580 - val_recall: 0.4515 - val_precision: 0.8057\n",
      "\n",
      "Epoch 00015: val_fmeasure improved from 57.54545 to 57.85804, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 16/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0117 - acc: 0.9962 - fmeasure: 59.2629 - recall: 0.4795 - precision: 0.7760 - val_loss: 0.0124 - val_acc: 0.9962 - val_fmeasure: 57.9963 - val_recall: 0.4534 - val_precision: 0.8051\n",
      "\n",
      "Epoch 00016: val_fmeasure improved from 57.85804 to 57.99629, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 17/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0116 - acc: 0.9963 - fmeasure: 59.5980 - recall: 0.4830 - precision: 0.7785 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 58.0375 - val_recall: 0.4532 - val_precision: 0.8074\n",
      "\n",
      "Epoch 00017: val_fmeasure improved from 57.99629 to 58.03753, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 18/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0114 - acc: 0.9963 - fmeasure: 59.9510 - recall: 0.4871 - precision: 0.7800 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 57.9562 - val_recall: 0.4512 - val_precision: 0.8106\n",
      "\n",
      "Epoch 00018: val_fmeasure did not improve from 58.03753\n",
      "Epoch 19/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0113 - acc: 0.9963 - fmeasure: 60.3014 - recall: 0.4906 - precision: 0.7828 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 58.3336 - val_recall: 0.4571 - val_precision: 0.8066\n",
      "\n",
      "Epoch 00019: val_fmeasure improved from 58.03753 to 58.33363, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 20/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0111 - acc: 0.9963 - fmeasure: 60.5320 - recall: 0.4931 - precision: 0.7841 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 58.4974 - val_recall: 0.4593 - val_precision: 0.8059\n",
      "\n",
      "Epoch 00020: val_fmeasure improved from 58.33363 to 58.49744, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 21/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0110 - acc: 0.9964 - fmeasure: 60.9165 - recall: 0.4976 - precision: 0.7858 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 58.5292 - val_recall: 0.4596 - val_precision: 0.8063\n",
      "\n",
      "Epoch 00021: val_fmeasure improved from 58.49744 to 58.52919, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 22/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0109 - acc: 0.9964 - fmeasure: 61.1689 - recall: 0.5003 - precision: 0.7875 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 58.5463 - val_recall: 0.4592 - val_precision: 0.8080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: val_fmeasure improved from 58.52919 to 58.54630, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 23/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0108 - acc: 0.9964 - fmeasure: 61.4437 - recall: 0.5033 - precision: 0.7891 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 58.6516 - val_recall: 0.4604 - val_precision: 0.8083\n",
      "\n",
      "Epoch 00023: val_fmeasure improved from 58.54630 to 58.65163, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 24/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0106 - acc: 0.9964 - fmeasure: 61.6767 - recall: 0.5059 - precision: 0.7903 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 58.8264 - val_recall: 0.4637 - val_precision: 0.8050\n",
      "\n",
      "Epoch 00024: val_fmeasure improved from 58.65163 to 58.82641, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 25/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0105 - acc: 0.9964 - fmeasure: 61.9450 - recall: 0.5090 - precision: 0.7917 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 58.8996 - val_recall: 0.4643 - val_precision: 0.8059\n",
      "\n",
      "Epoch 00025: val_fmeasure improved from 58.82641 to 58.89960, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 26/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0104 - acc: 0.9965 - fmeasure: 62.2338 - recall: 0.5123 - precision: 0.7930 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 58.9099 - val_recall: 0.4640 - val_precision: 0.8072\n",
      "\n",
      "Epoch 00026: val_fmeasure improved from 58.89960 to 58.90988, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 27/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0103 - acc: 0.9965 - fmeasure: 62.4238 - recall: 0.5143 - precision: 0.7945 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 58.9511 - val_recall: 0.4644 - val_precision: 0.8076\n",
      "\n",
      "Epoch 00027: val_fmeasure improved from 58.90988 to 58.95106, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 28/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0102 - acc: 0.9965 - fmeasure: 62.7346 - recall: 0.5179 - precision: 0.7959 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.1105 - val_recall: 0.4672 - val_precision: 0.805124 - recall: 0.51\n",
      "\n",
      "Epoch 00028: val_fmeasure improved from 58.95106 to 59.11047, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 29/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0101 - acc: 0.9965 - fmeasure: 62.9665 - recall: 0.5203 - precision: 0.7976 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.0967 - val_recall: 0.4666 - val_precision: 0.8064\n",
      "\n",
      "Epoch 00029: val_fmeasure did not improve from 59.11047\n",
      "Epoch 30/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0101 - acc: 0.9965 - fmeasure: 63.1475 - recall: 0.5226 - precision: 0.7982 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.1769 - val_recall: 0.4677 - val_precision: 0.8061\n",
      "\n",
      "Epoch 00030: val_fmeasure improved from 59.11047 to 59.17689, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 31/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0100 - acc: 0.9965 - fmeasure: 63.3758 - recall: 0.5253 - precision: 0.7992 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.1684 - val_recall: 0.4674 - val_precision: 0.8066\n",
      "\n",
      "Epoch 00031: val_fmeasure did not improve from 59.17689\n",
      "Epoch 32/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0099 - acc: 0.9966 - fmeasure: 63.5863 - recall: 0.5276 - precision: 0.8006 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.2691 - val_recall: 0.4691 - val_precision: 0.8052\n",
      "\n",
      "Epoch 00032: val_fmeasure improved from 59.17689 to 59.26911, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 33/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0098 - acc: 0.9966 - fmeasure: 63.7992 - recall: 0.5302 - precision: 0.8013 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.3009 - val_recall: 0.4697 - val_precision: 0.8047\n",
      "\n",
      "Epoch 00033: val_fmeasure improved from 59.26911 to 59.30089, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 34/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0098 - acc: 0.9966 - fmeasure: 63.9961 - recall: 0.5322 - precision: 0.8028 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.4842 - val_recall: 0.4723 - val_precision: 0.8037\n",
      "\n",
      "Epoch 00034: val_fmeasure improved from 59.30089 to 59.48420, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 35/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0097 - acc: 0.9966 - fmeasure: 64.1826 - recall: 0.5349 - precision: 0.8028 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.3765 - val_recall: 0.4701 - val_precision: 0.8064\n",
      "\n",
      "Epoch 00035: val_fmeasure did not improve from 59.48420\n",
      "Epoch 36/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0096 - acc: 0.9966 - fmeasure: 64.4144 - recall: 0.5375 - precision: 0.8040 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.3249 - val_recall: 0.4693 - val_precision: 0.80676 - p\n",
      "\n",
      "Epoch 00036: val_fmeasure did not improve from 59.48420\n",
      "Epoch 37/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0096 - acc: 0.9966 - fmeasure: 64.5387 - recall: 0.5389 - precision: 0.8048 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.4865 - val_recall: 0.4718 - val_precision: 0.8052\n",
      "\n",
      "Epoch 00037: val_fmeasure improved from 59.48420 to 59.48654, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 38/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0095 - acc: 0.9966 - fmeasure: 64.7784 - recall: 0.5420 - precision: 0.8054 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.4257 - val_recall: 0.4708 - val_precision: 0.8061\n",
      "\n",
      "Epoch 00038: val_fmeasure did not improve from 59.48654\n",
      "Epoch 39/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0094 - acc: 0.9967 - fmeasure: 64.9357 - recall: 0.5437 - precision: 0.8066 - val_loss: 0.0122 - val_acc: 0.9963 - val_fmeasure: 59.4288 - val_recall: 0.4708 - val_precision: 0.8062\n",
      "\n",
      "Epoch 00039: val_fmeasure did not improve from 59.48654\n",
      "Epoch 40/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0094 - acc: 0.9967 - fmeasure: 65.1468 - recall: 0.5462 - precision: 0.8074 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.4967 - val_recall: 0.4719 - val_precision: 0.8053\n",
      "\n",
      "Epoch 00040: val_fmeasure improved from 59.48654 to 59.49674, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 41/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0093 - acc: 0.9967 - fmeasure: 65.3875 - recall: 0.5491 - precision: 0.8084 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.4508 - val_recall: 0.4710 - val_precision: 0.8063\n",
      "\n",
      "Epoch 00041: val_fmeasure did not improve from 59.49674\n",
      "Epoch 42/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0093 - acc: 0.9967 - fmeasure: 65.4565 - recall: 0.5499 - precision: 0.8088 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.5095 - val_recall: 0.4721 - val_precision: 0.8054\n",
      "\n",
      "Epoch 00042: val_fmeasure improved from 59.49674 to 59.50951, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 43/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0092 - acc: 0.9967 - fmeasure: 65.6880 - recall: 0.5528 - precision: 0.8097 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.5334 - val_recall: 0.4719 - val_precision: 0.8067\n",
      "\n",
      "Epoch 00043: val_fmeasure improved from 59.50951 to 59.53343, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 44/200\n",
      "28000/28000 [==============================] - 11s 393us/step - loss: 0.0092 - acc: 0.9967 - fmeasure: 65.8766 - recall: 0.5551 - precision: 0.8105 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.7448 - val_recall: 0.4756 - val_precision: 0.8039\n",
      "\n",
      "Epoch 00044: val_fmeasure improved from 59.53343 to 59.74476, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 45/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0092 - acc: 0.9967 - fmeasure: 65.9780 - recall: 0.5563 - precision: 0.8109 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.5523 - val_recall: 0.4722 - val_precision: 0.8065\n",
      "\n",
      "Epoch 00045: val_fmeasure did not improve from 59.74476\n",
      "Epoch 46/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0091 - acc: 0.9967 - fmeasure: 66.1462 - recall: 0.5586 - precision: 0.8112 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.7031 - val_recall: 0.4747 - val_precision: 0.8047\n",
      "\n",
      "Epoch 00046: val_fmeasure did not improve from 59.74476\n",
      "Epoch 47/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0091 - acc: 0.9967 - fmeasure: 66.2873 - recall: 0.5603 - precision: 0.8119 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.6724 - val_recall: 0.4744 - val_precision: 0.8045\n",
      "\n",
      "Epoch 00047: val_fmeasure did not improve from 59.74476\n",
      "Epoch 48/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0090 - acc: 0.9968 - fmeasure: 66.4435 - recall: 0.5620 - precision: 0.8129 - val_loss: 0.0123 - val_acc: 0.9963 - val_fmeasure: 59.6764 - val_recall: 0.4741 - val_precision: 0.8057\n",
      "\n",
      "Epoch 00048: val_fmeasure did not improve from 59.74476\n",
      "Epoch 49/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0090 - acc: 0.9968 - fmeasure: 66.5869 - recall: 0.5637 - precision: 0.8137 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.6928 - val_recall: 0.4747 - val_precision: 0.8046\n",
      "\n",
      "Epoch 00049: val_fmeasure did not improve from 59.74476\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "Epoch 50/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0089 - acc: 0.9968 - fmeasure: 66.9163 - recall: 0.5673 - precision: 0.8159 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7465 - val_recall: 0.4750 - val_precision: 0.8055\n",
      "\n",
      "Epoch 00050: val_fmeasure improved from 59.74476 to 59.74652, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 51/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0089 - acc: 0.9968 - fmeasure: 67.0127 - recall: 0.5686 - precision: 0.8160 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7143 - val_recall: 0.4742 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00051: val_fmeasure did not improve from 59.74652\n",
      "Epoch 52/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0088 - acc: 0.9968 - fmeasure: 67.1055 - recall: 0.5695 - precision: 0.8172 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7753 - val_recall: 0.4751 - val_precision: 0.8063\n",
      "\n",
      "Epoch 00052: val_fmeasure improved from 59.74652 to 59.77528, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 53/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0088 - acc: 0.9968 - fmeasure: 67.1940 - recall: 0.5707 - precision: 0.8173 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7410 - val_recall: 0.4748 - val_precision: 0.8060\n",
      "\n",
      "Epoch 00053: val_fmeasure did not improve from 59.77528\n",
      "Epoch 54/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0088 - acc: 0.9968 - fmeasure: 67.2474 - recall: 0.5712 - precision: 0.8177 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7568 - val_recall: 0.4747 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00054: val_fmeasure did not improve from 59.77528\n",
      "Epoch 55/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0088 - acc: 0.9968 - fmeasure: 67.3921 - recall: 0.5730 - precision: 0.8183 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.6873 - val_recall: 0.4737 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00055: val_fmeasure did not improve from 59.77528\n",
      "Epoch 56/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0088 - acc: 0.9968 - fmeasure: 67.4054 - recall: 0.5730 - precision: 0.8187 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7909 - val_recall: 0.4752 - val_precision: 0.8067\n",
      "\n",
      "Epoch 00056: val_fmeasure improved from 59.77528 to 59.79093, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 57/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0087 - acc: 0.9968 - fmeasure: 67.5160 - recall: 0.5743 - precision: 0.8193 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7570 - val_recall: 0.4749 - val_precision: 0.8063\n",
      "\n",
      "Epoch 00057: val_fmeasure did not improve from 59.79093\n",
      "Epoch 58/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0087 - acc: 0.9968 - fmeasure: 67.5316 - recall: 0.5747 - precision: 0.8189 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7677 - val_recall: 0.4750 - val_precision: 0.8065\n",
      "\n",
      "Epoch 00058: val_fmeasure did not improve from 59.79093\n",
      "Epoch 59/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0087 - acc: 0.9969 - fmeasure: 67.6301 - recall: 0.5757 - precision: 0.8199 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7717 - val_recall: 0.4749 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00059: val_fmeasure did not improve from 59.79093\n",
      "Epoch 60/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0087 - acc: 0.9969 - fmeasure: 67.6920 - recall: 0.5767 - precision: 0.8196 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7468 - val_recall: 0.4748 - val_precision: 0.8061\n",
      "\n",
      "Epoch 00060: val_fmeasure did not improve from 59.79093\n",
      "Epoch 61/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0087 - acc: 0.9969 - fmeasure: 67.7628 - recall: 0.5775 - precision: 0.8201 - val_loss: 0.0124 - val_acc: 0.9963 - val_fmeasure: 59.7570 - val_recall: 0.4746 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00061: val_fmeasure did not improve from 59.79093\n",
      "\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Epoch 62/200\n",
      "28000/28000 [==============================] - 11s 385us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 67.9328 - recall: 0.5791 - precision: 0.8218 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8105 - val_recall: 0.4754 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00062: val_fmeasure improved from 59.79093 to 59.81049, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 63/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 67.9279 - recall: 0.5791 - precision: 0.8218 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8090 - val_recall: 0.4754 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00063: val_fmeasure did not improve from 59.81049\n",
      "Epoch 64/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 67.9980 - recall: 0.5801 - precision: 0.8217 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8397 - val_recall: 0.4760 - val_precision: 0.8062\n",
      "\n",
      "Epoch 00064: val_fmeasure improved from 59.81049 to 59.83967, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 65/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 68.0139 - recall: 0.5803 - precision: 0.8217 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.7865 - val_recall: 0.4749 - val_precision: 0.8074\n",
      "\n",
      "Epoch 00065: val_fmeasure did not improve from 59.83967\n",
      "Epoch 66/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 68.0613 - recall: 0.5806 - precision: 0.8227 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.7816 - val_recall: 0.4748 - val_precision: 0.8073\n",
      "\n",
      "Epoch 00066: val_fmeasure did not improve from 59.83967\n",
      "Epoch 67/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 68.0883 - recall: 0.5809 - precision: 0.8228 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8269 - val_recall: 0.4757 - val_precision: 0.8066\n",
      "\n",
      "Epoch 00067: val_fmeasure did not improve from 59.83967\n",
      "Epoch 68/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 68.1514 - recall: 0.5817 - precision: 0.8229 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8715 - val_recall: 0.4765 - val_precision: 0.8059\n",
      "\n",
      "Epoch 00068: val_fmeasure improved from 59.83967 to 59.87146, saving model to embedding.best_dropout0.7_9_20.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 68.1603 - recall: 0.5820 - precision: 0.8227 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8254 - val_recall: 0.4755 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00069: val_fmeasure did not improve from 59.87146\n",
      "Epoch 70/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 68.1659 - recall: 0.5819 - precision: 0.8230 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8840 - val_recall: 0.4763 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00070: val_fmeasure improved from 59.87146 to 59.88396, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 71/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0086 - acc: 0.9969 - fmeasure: 68.2347 - recall: 0.5827 - precision: 0.8235 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8327 - val_recall: 0.4757 - val_precision: 0.8066\n",
      "\n",
      "Epoch 00071: val_fmeasure did not improve from 59.88396\n",
      "Epoch 72/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.2562 - recall: 0.5830 - precision: 0.8235 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8594 - val_recall: 0.4761 - val_precision: 0.8066\n",
      "\n",
      "Epoch 00072: val_fmeasure did not improve from 59.88396\n",
      "Epoch 73/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.2441 - recall: 0.5827 - precision: 0.8237 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.9197 - val_recall: 0.4771 - val_precision: 0.8057\n",
      "\n",
      "Epoch 00073: val_fmeasure improved from 59.88396 to 59.91971, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 74/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.3725 - recall: 0.5844 - precision: 0.8242 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8634 - val_recall: 0.4763 - val_precision: 0.8060\n",
      "\n",
      "Epoch 00074: val_fmeasure did not improve from 59.91971\n",
      "Epoch 75/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.3257 - recall: 0.5840 - precision: 0.8235 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8613 - val_recall: 0.4762 - val_precision: 0.8064\n",
      "\n",
      "Epoch 00075: val_fmeasure did not improve from 59.91971\n",
      "Epoch 76/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.3646 - recall: 0.5843 - precision: 0.8241 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8805 - val_recall: 0.4764 - val_precision: 0.8063\n",
      "\n",
      "Epoch 00076: val_fmeasure did not improve from 59.91971\n",
      "Epoch 77/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.4513 - recall: 0.5853 - precision: 0.8245 - val_loss: 0.0124 - val_acc: 0.9964 - val_fmeasure: 59.8407 - val_recall: 0.4758 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00077: val_fmeasure did not improve from 59.91971\n",
      "Epoch 78/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.4216 - recall: 0.5852 - precision: 0.8239 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8677 - val_recall: 0.4761 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00078: val_fmeasure did not improve from 59.91971\n",
      "\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Epoch 79/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.5466 - recall: 0.5862 - precision: 0.8255 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8748 - val_recall: 0.4762 - val_precision: 0.8069\n",
      "\n",
      "Epoch 00079: val_fmeasure did not improve from 59.91971\n",
      "Epoch 80/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.5744 - recall: 0.5863 - precision: 0.8260 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8800 - val_recall: 0.4763 - val_precision: 0.8067\n",
      "\n",
      "Epoch 00080: val_fmeasure did not improve from 59.91971\n",
      "Epoch 81/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.5727 - recall: 0.5865 - precision: 0.8258 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8967 - val_recall: 0.4767 - val_precision: 0.8061\n",
      "\n",
      "Epoch 00081: val_fmeasure did not improve from 59.91971\n",
      "Epoch 82/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.5997 - recall: 0.5870 - precision: 0.8255 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9227 - val_recall: 0.4769 - val_precision: 0.8065\n",
      "\n",
      "Epoch 00082: val_fmeasure improved from 59.91971 to 59.92265, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 83/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.6439 - recall: 0.5875 - precision: 0.8257 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9144 - val_recall: 0.4768 - val_precision: 0.8066\n",
      "\n",
      "Epoch 00083: val_fmeasure did not improve from 59.92265\n",
      "Epoch 84/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0085 - acc: 0.9969 - fmeasure: 68.6367 - recall: 0.5875 - precision: 0.8256 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8981 - val_recall: 0.4766 - val_precision: 0.8065\n",
      "\n",
      "Epoch 00084: val_fmeasure did not improve from 59.92265\n",
      "Epoch 85/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.6409 - recall: 0.5875 - precision: 0.8257 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8980 - val_recall: 0.4764 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00085: val_fmeasure did not improve from 59.92265\n",
      "Epoch 86/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.6407 - recall: 0.5874 - precision: 0.8260 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9302 - val_recall: 0.4772 - val_precision: 0.8061\n",
      "\n",
      "Epoch 00086: val_fmeasure improved from 59.92265 to 59.93025, saving model to embedding.best_dropout0.7_9_20.hdf5\n",
      "Epoch 87/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.6741 - recall: 0.5880 - precision: 0.8256 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8753 - val_recall: 0.4761 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00087: val_fmeasure did not improve from 59.93025\n",
      "Epoch 88/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.7032 - recall: 0.5881 - precision: 0.8263 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8923 - val_recall: 0.4765 - val_precision: 0.8067\n",
      "\n",
      "Epoch 00088: val_fmeasure did not improve from 59.93025\n",
      "Epoch 89/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.6887 - recall: 0.5881 - precision: 0.8260 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8877 - val_recall: 0.4762 - val_precision: 0.8072\n",
      "\n",
      "Epoch 00089: val_fmeasure did not improve from 59.93025\n",
      "Epoch 90/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.7294 - recall: 0.5885 - precision: 0.8263 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9106 - val_recall: 0.4767 - val_precision: 0.8066\n",
      "\n",
      "Epoch 00090: val_fmeasure did not improve from 59.93025\n",
      "Epoch 91/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.7804 - recall: 0.5890 - precision: 0.8268 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8878 - val_recall: 0.4763 - val_precision: 0.8069\n",
      "\n",
      "Epoch 00091: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Epoch 92/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.7796 - recall: 0.5890 - precision: 0.8267 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8927 - val_recall: 0.4763 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00092: val_fmeasure did not improve from 59.93025\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8545 - recall: 0.5900 - precision: 0.8269 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8986 - val_recall: 0.4765 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00093: val_fmeasure did not improve from 59.93025\n",
      "Epoch 94/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8102 - recall: 0.5892 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8926 - val_recall: 0.4763 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00094: val_fmeasure did not improve from 59.93025\n",
      "Epoch 95/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9969 - fmeasure: 68.7663 - recall: 0.5889 - precision: 0.8266 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8936 - val_recall: 0.4764 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00095: val_fmeasure did not improve from 59.93025\n",
      "Epoch 96/200\n",
      "28000/28000 [==============================] - 11s 384us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8232 - recall: 0.5894 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8894 - val_recall: 0.4764 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00096: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Epoch 97/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8214 - recall: 0.5897 - precision: 0.8266 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8856 - val_recall: 0.4763 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00097: val_fmeasure did not improve from 59.93025\n",
      "Epoch 98/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.7916 - recall: 0.5891 - precision: 0.8269 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8950 - val_recall: 0.4764 - val_precision: 0.8069\n",
      "\n",
      "Epoch 00098: val_fmeasure did not improve from 59.93025\n",
      "Epoch 99/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8474 - recall: 0.5896 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9017 - val_recall: 0.4765 - val_precision: 0.8069\n",
      "\n",
      "Epoch 00099: val_fmeasure did not improve from 59.93025\n",
      "Epoch 100/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8850 - recall: 0.5901 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9023 - val_recall: 0.4765 - val_precision: 0.8068\n",
      "\n",
      "Epoch 00100: val_fmeasure did not improve from 59.93025\n",
      "Epoch 101/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8293 - recall: 0.5897 - precision: 0.8268 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8973 - val_recall: 0.4764 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00101: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00101: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "Epoch 102/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9258 - recall: 0.5906 - precision: 0.8278 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9002 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00102: val_fmeasure did not improve from 59.93025\n",
      "Epoch 103/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8218 - recall: 0.5894 - precision: 0.8271 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8969 - val_recall: 0.4764 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00103: val_fmeasure did not improve from 59.93025\n",
      "Epoch 104/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8977 - recall: 0.5904 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8961 - val_recall: 0.4764 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00104: val_fmeasure did not improve from 59.93025\n",
      "Epoch 105/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8692 - recall: 0.5900 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.8980 - val_recall: 0.4764 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00105: val_fmeasure did not improve from 59.93025\n",
      "Epoch 106/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9037 - recall: 0.5904 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9001 - val_recall: 0.4764 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00106: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00106: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "Epoch 107/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8892 - recall: 0.5903 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9012 - val_recall: 0.4764 - val_precision: 0.8072\n",
      "\n",
      "Epoch 00107: val_fmeasure did not improve from 59.93025\n",
      "Epoch 108/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8769 - recall: 0.5895 - precision: 0.8285 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9075 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00108: val_fmeasure did not improve from 59.93025\n",
      "Epoch 109/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9324 - recall: 0.5907 - precision: 0.8279 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9041 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00109: val_fmeasure did not improve from 59.93025\n",
      "Epoch 110/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8259 - recall: 0.5896 - precision: 0.8268 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9039 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00110: val_fmeasure did not improve from 59.93025\n",
      "Epoch 111/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8326 - recall: 0.5895 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9100 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00111: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "Epoch 112/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9111 - recall: 0.5906 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9036 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00112: val_fmeasure did not improve from 59.93025\n",
      "Epoch 113/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9082 - recall: 0.5904 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9074 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00113: val_fmeasure did not improve from 59.93025\n",
      "Epoch 114/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9293 - recall: 0.5908 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9044 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00114: val_fmeasure did not improve from 59.93025\n",
      "Epoch 115/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8459 - recall: 0.5897 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9059 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00115: val_fmeasure did not improve from 59.93025\n",
      "Epoch 116/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9112 - recall: 0.5904 - precision: 0.8279 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9041 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00116: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00116: ReduceLROnPlateau reducing learning rate to 1.9531249506599124e-07.\n",
      "Epoch 117/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8901 - recall: 0.5904 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9030 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00117: val_fmeasure did not improve from 59.93025\n",
      "Epoch 118/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9046 - recall: 0.5905 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9061 - val_recall: 0.4765 - val_precision: 0.8070 - acc: 0.9970 - fmeasure: 68.9006 - recall: 0.5905\n",
      "\n",
      "Epoch 00118: val_fmeasure did not improve from 59.93025\n",
      "Epoch 119/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8876 - recall: 0.5902 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00119: val_fmeasure did not improve from 59.93025\n",
      "Epoch 120/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8852 - recall: 0.5903 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9054 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00120: val_fmeasure did not improve from 59.93025\n",
      "Epoch 121/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8867 - recall: 0.5903 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9068 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00121: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 9.765624753299562e-08.\n",
      "Epoch 122/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9028 - recall: 0.5902 - precision: 0.8279 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9071 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00122: val_fmeasure did not improve from 59.93025\n",
      "Epoch 123/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8791 - recall: 0.5903 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9062 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00123: val_fmeasure did not improve from 59.93025\n",
      "Epoch 124/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8492 - recall: 0.5897 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9060 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00124: val_fmeasure did not improve from 59.93025\n",
      "Epoch 125/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9267 - recall: 0.5905 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9067 - val_recall: 0.4765 - val_precision: 0.8071\n",
      "\n",
      "Epoch 00125: val_fmeasure did not improve from 59.93025\n",
      "Epoch 126/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8853 - recall: 0.5900 - precision: 0.8278 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9055 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00126: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00126: ReduceLROnPlateau reducing learning rate to 4.882812376649781e-08.\n",
      "Epoch 127/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8951 - recall: 0.5902 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9062 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00127: val_fmeasure did not improve from 59.93025\n",
      "Epoch 128/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9360 - recall: 0.5906 - precision: 0.8280 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9057 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00128: val_fmeasure did not improve from 59.93025\n",
      "Epoch 129/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8854 - recall: 0.5904 - precision: 0.8270 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9048 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00129: val_fmeasure did not improve from 59.93025\n",
      "Epoch 130/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8842 - recall: 0.5904 - precision: 0.8270 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9042 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00130: val_fmeasure did not improve from 59.93025\n",
      "Epoch 131/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9454 - recall: 0.5907 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9049 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00131: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 2.4414061883248905e-08.\n",
      "Epoch 132/200\n",
      "28000/28000 [==============================] - 11s 392us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8686 - recall: 0.5901 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9050 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00132: val_fmeasure did not improve from 59.93025\n",
      "Epoch 133/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8979 - recall: 0.5904 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9053 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00133: val_fmeasure did not improve from 59.93025\n",
      "Epoch 134/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9113 - recall: 0.5904 - precision: 0.8278 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9050 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00134: val_fmeasure did not improve from 59.93025\n",
      "Epoch 135/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8941 - recall: 0.5901 - precision: 0.8279 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9052 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00135: val_fmeasure did not improve from 59.93025\n",
      "Epoch 136/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8675 - recall: 0.5901 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9050 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00136: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00136: ReduceLROnPlateau reducing learning rate to 1.2207030941624453e-08.\n",
      "Epoch 137/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9088 - recall: 0.5906 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9050 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00137: val_fmeasure did not improve from 59.93025\n",
      "Epoch 138/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8944 - recall: 0.5903 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9048 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00138: val_fmeasure did not improve from 59.93025\n",
      "Epoch 139/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8491 - recall: 0.5897 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9052 - val_recall: 0.4765 - val_precision: 0.8070e: 68.8674 - recall: \n",
      "\n",
      "Epoch 00139: val_fmeasure did not improve from 59.93025\n",
      "Epoch 140/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9615 - recall: 0.5911 - precision: 0.8280 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9052 - val_recall: 0.4765 - val_precision: 0.8070: 0.9970 - fmeasure: 68.9764 - recall: 0.5913 - pre\n",
      "\n",
      "Epoch 00140: val_fmeasure did not improve from 59.93025\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8338 - recall: 0.5897 - precision: 0.8270 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9061 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00141: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00141: ReduceLROnPlateau reducing learning rate to 6.103515470812226e-09.\n",
      "Epoch 142/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8986 - recall: 0.5904 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9057 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00142: val_fmeasure did not improve from 59.93025\n",
      "Epoch 143/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9043 - recall: 0.5901 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9060 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00143: val_fmeasure did not improve from 59.93025\n",
      "Epoch 144/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8471 - recall: 0.5900 - precision: 0.8267 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9054 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00144: val_fmeasure did not improve from 59.93025\n",
      "Epoch 145/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9520 - recall: 0.5912 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9054 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00145: val_fmeasure did not improve from 59.93025\n",
      "Epoch 146/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9220 - recall: 0.5908 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9057 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00146: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00146: ReduceLROnPlateau reducing learning rate to 3.051757735406113e-09.\n",
      "Epoch 147/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8721 - recall: 0.5900 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9064 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00147: val_fmeasure did not improve from 59.93025\n",
      "Epoch 148/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8631 - recall: 0.5900 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9056 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00148: val_fmeasure did not improve from 59.93025\n",
      "Epoch 149/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8998 - recall: 0.5903 - precision: 0.8278 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9057 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00149: val_fmeasure did not improve from 59.93025\n",
      "Epoch 150/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8924 - recall: 0.5904 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9060 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00150: val_fmeasure did not improve from 59.93025\n",
      "Epoch 151/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9237 - recall: 0.5904 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9060 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00151: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 1.5258788677030566e-09.\n",
      "Epoch 152/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8309 - recall: 0.5895 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9064 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00152: val_fmeasure did not improve from 59.93025\n",
      "Epoch 153/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9378 - recall: 0.5910 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9067 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00153: val_fmeasure did not improve from 59.93025\n",
      "Epoch 154/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8615 - recall: 0.5900 - precision: 0.8271 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9067 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00154: val_fmeasure did not improve from 59.93025\n",
      "Epoch 155/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9097 - recall: 0.5905 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00155: val_fmeasure did not improve from 59.93025\n",
      "Epoch 156/200\n",
      "28000/28000 [==============================] - 11s 393us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9048 - recall: 0.5904 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00156: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00156: ReduceLROnPlateau reducing learning rate to 7.629394338515283e-10.\n",
      "Epoch 157/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8977 - recall: 0.5908 - precision: 0.8266 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00157: val_fmeasure did not improve from 59.93025\n",
      "Epoch 158/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8607 - recall: 0.5902 - precision: 0.8268 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00158: val_fmeasure did not improve from 59.93025\n",
      "Epoch 159/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9240 - recall: 0.5907 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00159: val_fmeasure did not improve from 59.93025\n",
      "Epoch 160/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9078 - recall: 0.5906 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00160: val_fmeasure did not improve from 59.93025\n",
      "Epoch 161/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8838 - recall: 0.5898 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00161: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00161: ReduceLROnPlateau reducing learning rate to 3.8146971692576415e-10.\n",
      "Epoch 162/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8643 - recall: 0.5902 - precision: 0.8269 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00162: val_fmeasure did not improve from 59.93025\n",
      "Epoch 163/200\n",
      "28000/28000 [==============================] - 11s 385us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9180 - recall: 0.5903 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00163: val_fmeasure did not improve from 59.93025\n",
      "Epoch 164/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8985 - recall: 0.5904 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00164: val_fmeasure did not improve from 59.93025\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8365 - recall: 0.5897 - precision: 0.8271 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00165: val_fmeasure did not improve from 59.93025\n",
      "Epoch 166/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8470 - recall: 0.5896 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00166: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00166: ReduceLROnPlateau reducing learning rate to 1.9073485846288207e-10.\n",
      "Epoch 167/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9163 - recall: 0.5904 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00167: val_fmeasure did not improve from 59.93025\n",
      "Epoch 168/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8704 - recall: 0.5899 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00168: val_fmeasure did not improve from 59.93025\n",
      "Epoch 169/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8490 - recall: 0.5898 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00169: val_fmeasure did not improve from 59.93025\n",
      "Epoch 170/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8994 - recall: 0.5905 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00170: val_fmeasure did not improve from 59.93025\n",
      "Epoch 171/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8993 - recall: 0.5905 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00171: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 9.536742923144104e-11.\n",
      "Epoch 172/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8698 - recall: 0.5902 - precision: 0.8270 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070measure: 68.8460 - recall: 0.5898 - precision\n",
      "\n",
      "Epoch 00172: val_fmeasure did not improve from 59.93025\n",
      "Epoch 173/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8637 - recall: 0.5899 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00173: val_fmeasure did not improve from 59.93025\n",
      "Epoch 174/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9071 - recall: 0.5905 - precision: 0.8274 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00174: val_fmeasure did not improve from 59.93025\n",
      "Epoch 175/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9127 - recall: 0.5905 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00175: val_fmeasure did not improve from 59.93025\n",
      "Epoch 176/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9075 - recall: 0.5903 - precision: 0.8280 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00176: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00176: ReduceLROnPlateau reducing learning rate to 4.768371461572052e-11.\n",
      "Epoch 177/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8826 - recall: 0.5900 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00177: val_fmeasure did not improve from 59.93025\n",
      "Epoch 178/200\n",
      "28000/28000 [==============================] - 11s 391us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8507 - recall: 0.5896 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00178: val_fmeasure did not improve from 59.93025\n",
      "Epoch 179/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9033 - recall: 0.5908 - precision: 0.8268 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00179: val_fmeasure did not improve from 59.93025\n",
      "Epoch 180/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9138 - recall: 0.5907 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00180: val_fmeasure did not improve from 59.93025\n",
      "Epoch 181/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8970 - recall: 0.5902 - precision: 0.8278 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00181: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00181: ReduceLROnPlateau reducing learning rate to 2.384185730786026e-11.\n",
      "Epoch 182/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8461 - recall: 0.5897 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00182: val_fmeasure did not improve from 59.93025\n",
      "Epoch 183/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9079 - recall: 0.5903 - precision: 0.8279 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00183: val_fmeasure did not improve from 59.93025\n",
      "Epoch 184/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8956 - recall: 0.5904 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00184: val_fmeasure did not improve from 59.93025\n",
      "Epoch 185/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9368 - recall: 0.5909 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00185: val_fmeasure did not improve from 59.93025\n",
      "Epoch 186/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8969 - recall: 0.5905 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00186: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00186: ReduceLROnPlateau reducing learning rate to 1.192092865393013e-11.\n",
      "Epoch 187/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8879 - recall: 0.5904 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00187: val_fmeasure did not improve from 59.93025\n",
      "Epoch 188/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8648 - recall: 0.5902 - precision: 0.8269 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00188: val_fmeasure did not improve from 59.93025\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9148 - recall: 0.5909 - precision: 0.8270 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00189: val_fmeasure did not improve from 59.93025\n",
      "Epoch 190/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8637 - recall: 0.5897 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00190: val_fmeasure did not improve from 59.93025\n",
      "Epoch 191/200\n",
      "28000/28000 [==============================] - 11s 386us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9419 - recall: 0.5911 - precision: 0.8272 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00191: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00191: ReduceLROnPlateau reducing learning rate to 5.960464326965065e-12.\n",
      "Epoch 192/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8959 - recall: 0.5902 - precision: 0.8277 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00192: val_fmeasure did not improve from 59.93025\n",
      "Epoch 193/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9338 - recall: 0.5909 - precision: 0.8275 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00193: val_fmeasure did not improve from 59.93025\n",
      "Epoch 194/200\n",
      "28000/28000 [==============================] - 11s 387us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8534 - recall: 0.5902 - precision: 0.8265 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00194: val_fmeasure did not improve from 59.93025\n",
      "Epoch 195/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9025 - recall: 0.5903 - precision: 0.8278 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00195: val_fmeasure did not improve from 59.93025\n",
      "Epoch 196/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8941 - recall: 0.5899 - precision: 0.8282 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00196: val_fmeasure did not improve from 59.93025\n",
      "\n",
      "Epoch 00196: ReduceLROnPlateau reducing learning rate to 2.9802321634825324e-12.\n",
      "Epoch 197/200\n",
      "28000/28000 [==============================] - 11s 388us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9629 - recall: 0.5910 - precision: 0.8281 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00197: val_fmeasure did not improve from 59.93025\n",
      "Epoch 198/200\n",
      "28000/28000 [==============================] - 11s 389us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8899 - recall: 0.5903 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00198: val_fmeasure did not improve from 59.93025\n",
      "Epoch 199/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.9217 - recall: 0.5907 - precision: 0.8276 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00199: val_fmeasure did not improve from 59.93025\n",
      "Epoch 200/200\n",
      "28000/28000 [==============================] - 11s 390us/step - loss: 0.0084 - acc: 0.9970 - fmeasure: 68.8618 - recall: 0.5899 - precision: 0.8273 - val_loss: 0.0125 - val_acc: 0.9964 - val_fmeasure: 59.9065 - val_recall: 0.4765 - val_precision: 0.8070\n",
      "\n",
      "Epoch 00200: val_fmeasure did not improve from 59.93025\n"
     ]
    }
   ],
   "source": [
    "#搭建融合后的模型\n",
    "inputs = Input((X_train.shape[1:]))\n",
    "x = Dropout(0.7)(inputs)\n",
    "x = Dense(6941, activation='sigmoid')(x)\n",
    "model = Model(inputs, x)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='embedding.best_dropout0.7_9_20.hdf5',monitor='val_fmeasure',mode='max',\n",
    "                               verbose=1, save_best_only=True) #保存最好模型权重\n",
    "reduce = ReduceLROnPlateau(monitor='val_fmeasure',factor=0.5,patience=5,verbose=1,mode='max')\n",
    "adam = Adam(0.0001)\n",
    "model.compile(optimizer = adam,\n",
    "           loss='binary_crossentropy',\n",
    "           metrics=['accuracy',fmeasure,recall,precision])\n",
    "epochs = 200\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    epochs=epochs, batch_size=128,callbacks=[checkpointer,reduce],verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型预测，得到结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('embedding.best_dropout0.7_9_20_59.93025.hdf5')\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python\n",
    "threshold = 0.5\n",
    "def arr2tag(arr):\n",
    "    tags = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        tag = []\n",
    "        index = np.where(arr[i] > threshold)  \n",
    "        index = index[0].tolist()\n",
    "        tag =  [hash_tag[j] for j in index]\n",
    "        tags.append(tag)\n",
    "    return tags\n",
    "y_tags = arr2tag(y_pred)\n",
    "\n",
    "import os\n",
    "img_name = os.listdir('test/')\n",
    "\n",
    "df = pd.DataFrame({'img_path':img_name, 'tags':y_tags})\n",
    "for i in range(df['tags'].shape[0]):\n",
    "    df['tags'].iloc[i] = ','.join(str(e) for e in  df['tags'].iloc[i])\n",
    "df.to_csv('merged_moudle_best9_27_3_%s.csv'%(threshold),index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
